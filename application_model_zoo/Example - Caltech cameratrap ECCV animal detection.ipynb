{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20Caltech%20cameratrap%20ECCV%20animal%20detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the network\n",
    "\n",
    "1. Paper on Focal Loss: https://arxiv.org/abs/1708.02002\n",
    "\n",
    "2. Blog 1 on RetinaNet: https://medium.com/@14prakash/the-intuition-behind-retinanet-eb636755607d\n",
    "\n",
    "3. Blog 2 on RetinaNet: https://blog.zenggyu.com/en/post/2018-12-05/retinanet-explained-and-demystified/\n",
    "\n",
    "4. Blog 3 on RetinaNet: https://towardsdatascience.com/review-retinanet-focal-loss-object-detection-38fba6afabe4\n",
    "\n",
    "5. Blog 4 on RetinaNet: https://analyticsindiamag.com/what-is-retinanet-ssd-focal-loss/\n",
    "\n",
    "6. Blog 5 on RetinaNet: https://towardsdatascience.com/object-detection-on-aerial-imagery-using-retinanet-626130ba2203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "\n",
    "## 1. Installattion Instructions\n",
    "\n",
    "\n",
    "## 2. Use trained model to detect animals in cameratrap images\n",
    "\n",
    "\n",
    "## 3. How to train using caltech-cameratrap dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    " - Run these commands\n",
    "     \n",
    "     - git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n",
    "     \n",
    "     - cd Monk_Object_Detection/5_pytorch_retinanet/installation\n",
    "     \n",
    " - Select the right requirements file and run\n",
    " \n",
    "     - cat requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colab use the command below\n",
    "! cd Monk_Object_Detection/5_pytorch_retinanet/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install\n",
    "\n",
    "# For Local systems and cloud select the other file\n",
    "#! cd Monk_Object_Detection/5_pytorch_retinanet/installation && cat requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use already trained model for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/5_pytorch_retinanet/lib/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_detector import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1X7o3lgyIp5Pn68Az0hvTfbqAH8TxKd1f' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1X7o3lgyIp5Pn68Az0hvTfbqAH8TxKd1f\" -O obj_cameratrap_2_trained.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq obj_cameratrap_2_trained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model(model_path=\"trained_model/final_model.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"trained_model/classes.txt\", 'r');\n",
    "class_list = f.readlines();\n",
    "f.close();\n",
    "for i in range(len(class_list)):\n",
    "    class_list[i] = class_list[i][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"trained_model/test/1.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"trained_model/test/2.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"trained_model/test/3.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"trained_model/test/4.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"trained_model/test/5.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"trained_model/test/6.jpg\";\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your own detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "    - Credits: https://beerys.github.io/CaltechCameraTraps/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/instances_images.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [];\n",
    "for i in range(100):\n",
    "    class_list.append(\"\");\n",
    "    \n",
    "for i in range(len(data[\"categories\"])):\n",
    "    class_list[data[\"categories\"][i][\"id\"]] = data[\"categories\"][i][\"name\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"annotations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"annotations\"]), len(os.listdir(\"dataset/images\")), len(data[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "image_names = [];\n",
    "bboxes = [];\n",
    "ids = [];\n",
    "\n",
    "for i in tqdm(range(len(data[\"annotations\"]))):\n",
    "    if('bbox' in data[\"annotations\"][i].keys()):\n",
    "        image_id = data[\"annotations\"][i][\"image_id\"];\n",
    "        bbox = data[\"annotations\"][i][\"bbox\"];\n",
    "        label = class_list[data[\"annotations\"][i][\"category_id\"]];\n",
    "        if(image_id not in image_names):\n",
    "            image_names.append(image_id);\n",
    "            bboxes.append([]);\n",
    "            ids.append([]);\n",
    "            \n",
    "\n",
    "        index = image_names.index(image_id);\n",
    "        bboxes[index].append(bbox)\n",
    "        ids[index].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_names), len(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [];\n",
    "for i in tqdm(range(len(image_names))):\n",
    "    img_name = image_names[i] + \".jpg\";\n",
    "    wr= \"\";\n",
    "    for j in range(len(bboxes[i])):\n",
    "        x1 = int(bboxes[i][j][0]);\n",
    "        y1 = int(bboxes[i][j][1]);\n",
    "        w = int(bboxes[i][j][2]);\n",
    "        h = int(bboxes[i][j][3]);\n",
    "        x2 = x1 + w;\n",
    "        y2 = y1 + h; \n",
    "        label = ids[i][j];\n",
    "        \n",
    "        wr += str(x1) + \" \" + str(y1) + \" \" + str(x2) + \" \" + str(y2) + \" \" + label + \" \";\n",
    "    \n",
    "    wr = wr[:len(wr)-1];\n",
    "    \n",
    "    combined.append([img_name, wr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(combined, columns = ['Id', 'Label'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset/train_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import dicttoxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import parseString\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"dataset/\";\n",
    "img_dir = \"images/\";\n",
    "anno_file = \"train_labels.csv\";\n",
    "\n",
    "dataset_path = root;\n",
    "images_folder = root + \"/\" + img_dir;\n",
    "annotations_path = root + \"/annotations/\";\n",
    "\n",
    "if not os.path.isdir(annotations_path):\n",
    "    os.mkdir(annotations_path)\n",
    "    \n",
    "input_images_folder = images_folder;\n",
    "input_annotations_path = root + \"/\" + anno_file;\n",
    "\n",
    "output_dataset_path = root;\n",
    "output_image_folder = input_images_folder;\n",
    "output_annotation_folder = annotations_path;\n",
    "\n",
    "tmp = img_dir.replace(\"/\", \"\");\n",
    "output_annotation_file = output_annotation_folder + \"/instances_\" + tmp + \".json\";\n",
    "output_classes_file = output_annotation_folder + \"/classes.txt\";\n",
    "\n",
    "if not os.path.isdir(output_annotation_folder):\n",
    "    os.mkdir(output_annotation_folder);\n",
    "    \n",
    "df = pd.read_csv(input_annotations_path);\n",
    "columns = df.columns\n",
    "\n",
    "delimiter = \" \";\n",
    "\n",
    "list_dict = [];\n",
    "anno = [];\n",
    "for i in range(len(df)):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    for j in range(len(tmp)//5):\n",
    "        label = tmp[j*5+4];\n",
    "        if(label not in anno):\n",
    "            anno.append(label);\n",
    "    anno = sorted(anno)\n",
    "    \n",
    "for i in tqdm(range(len(anno))):\n",
    "    tmp = {};\n",
    "    tmp[\"supercategory\"] = \"master\";\n",
    "    tmp[\"id\"] = i;\n",
    "    tmp[\"name\"] = anno[i];\n",
    "    list_dict.append(tmp);\n",
    "\n",
    "anno_f = open(output_classes_file, 'w');\n",
    "for i in range(len(anno)):\n",
    "    anno_f.write(anno[i] + \"\\n\");\n",
    "anno_f.close();\n",
    "\n",
    "\n",
    "coco_data = {};\n",
    "coco_data[\"type\"] = \"instances\";\n",
    "coco_data[\"images\"] = [];\n",
    "coco_data[\"annotations\"] = [];\n",
    "coco_data[\"categories\"] = list_dict;\n",
    "image_id = 0;\n",
    "annotation_id = 0;\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    image_in_path = input_images_folder + \"/\" + img_name;\n",
    "    img = cv2.imread(image_in_path, 1);\n",
    "    h, w, c = img.shape;\n",
    "\n",
    "    images_tmp = {};\n",
    "    images_tmp[\"file_name\"] = img_name;\n",
    "    images_tmp[\"height\"] = h;\n",
    "    images_tmp[\"width\"] = w;\n",
    "    images_tmp[\"id\"] = image_id;\n",
    "    coco_data[\"images\"].append(images_tmp);\n",
    "    \n",
    "\n",
    "    for j in range(len(tmp)//5):\n",
    "        x1 = int(tmp[j*5+0]);\n",
    "        y1 = int(tmp[j*5+1]);\n",
    "        x2 = int(tmp[j*5+2]);\n",
    "        y2 = int(tmp[j*5+3]);\n",
    "        label = tmp[j*5+4];\n",
    "        annotations_tmp = {};\n",
    "        annotations_tmp[\"id\"] = annotation_id;\n",
    "        annotation_id += 1;\n",
    "        annotations_tmp[\"image_id\"] = image_id;\n",
    "        annotations_tmp[\"segmentation\"] = [];\n",
    "        annotations_tmp[\"ignore\"] = 0;\n",
    "        annotations_tmp[\"area\"] = (x2-x1)*(y2-y1);\n",
    "        annotations_tmp[\"iscrowd\"] = 0;\n",
    "        annotations_tmp[\"bbox\"] = [x1, y1, x2-x1, y2-y1];\n",
    "        annotations_tmp[\"category_id\"] = anno.index(label);\n",
    "\n",
    "        coco_data[\"annotations\"].append(annotations_tmp)\n",
    "    image_id += 1;\n",
    "\n",
    "outfile =  open(output_annotation_file, 'w');\n",
    "json_str = json.dumps(coco_data, indent=4);\n",
    "outfile.write(json_str);\n",
    "outfile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your own detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/5_pytorch_retinanet/lib/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_detector import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Detector();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"dataset/\";\n",
    "coco_dir = \"\";\n",
    "img_dir = \"\";\n",
    "set_dir = \"images\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train_Dataset(root_dir, coco_dir, img_dir, set_dir, batch_size=16, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model(model_name=\"resnet34\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Set_Hyperparams(lr=0.0001, val_interval=1, print_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train(num_epochs=100, output_model_name=\"final_model.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/5_pytorch_retinanet/lib/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_detector import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model(model_path=\"final_model.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dataset/annotations/classes.txt\", 'r');\n",
    "class_list = f.readlines();\n",
    "f.close();\n",
    "for i in range(len(class_list)):\n",
    "    class_list[i] = class_list[i][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir(\"dataset/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"dataset/images/\" + lst[0];\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"dataset/images/\" + lst[1];\n",
    "scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.4);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
