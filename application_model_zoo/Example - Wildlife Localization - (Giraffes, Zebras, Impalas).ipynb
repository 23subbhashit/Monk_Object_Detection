{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/Monk_Object_Detection/blob/master/example_notebooks/10_pytorch_efficientdet/Train%20-%20with%20validation%20dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the network\n",
    "\n",
    "1. Paper on EfficientDet: https://arxiv.org/abs/1911.09070\n",
    "\n",
    "2. Blog 1 on EfficientDet: https://towardsdatascience.com/efficientdet-scalable-and-efficient-object-detection-review-4472ffc34fd9\n",
    "\n",
    "3. Blog 2 on EfficientDet: https://medium.com/@nainaakash012/efficientdet-scalable-and-efficient-object-detection-ea05ccd28427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "\n",
    "## 1. Installation Instructions\n",
    "\n",
    "\n",
    "\n",
    "## 2. Use trained model to detect traffic signs in images\n",
    "\n",
    "\n",
    "\n",
    "## 3. How to train using Lisa Traffic Sign Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    " - Run these commands\n",
    "     \n",
    "     - git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n",
    "     \n",
    "     - cd Monk_Object_Detection/10_pytorch_efficientdet/installation\n",
    "     \n",
    " - Select the right requirements file and run\n",
    " \n",
    "     - cat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colab use the command below\n",
    "! cd Monk_Object_Detection/10_pytorch_efficientdet/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install\n",
    "# Restart colab runtime now\n",
    "\n",
    "# For Local systems and cloud select the right CUDA version\n",
    "# ! cd Monk_Object_Detection/10_pytorch_efficientdet/installation && cat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use already trained model for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/10_pytorch_efficientdet/lib/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_detector import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1U0kZ-wLgUxIX1e270wybgE_uF897Fmxe' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1U0kZ-wLgUxIX1e270wybgE_uF897Fmxe\" -O wildlife_localization_trained.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq wildlife_localization_trained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"trained_weights/custom/classes.txt\", 'r');\n",
    "classes_list = f.readlines();\n",
    "f.close();\n",
    "\n",
    "for i in range(len(classes_list)):\n",
    "    classes_list[i] = classes_list[i][:len(classes_list[i])-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"trained_weights/custom/efficientdet-d3_trained.pth\";\n",
    "gtf.load_model(model_path, classes_list, use_gpu=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"trained_weights/test/2.jpg\", threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"trained_weights/test/3.jpg\", threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"trained_weights/test/8.jpg\", threshold=0.3);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"trained_weights/test/7.jpg\", threshold=0.3);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"trained_weights/test/6.jpg\", threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"trained_weights/test/5.jpg\", threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"trained_weights/test/4.jpg\", threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"trained_weights/test/1.jpg\", threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your own detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset credits\n",
    "    - Download link: https://lev.cs.rpi.edu/public/datasets/wild.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.isdir(\"dataset\")):\n",
    "    os.mkdir(\"dataset\");\n",
    "if(not os.path.isdir(\"dataset/train\")):\n",
    "    os.mkdir(\"dataset/train\");\n",
    "if(not os.path.isdir(\"dataset/val\")):\n",
    "    os.mkdir(\"dataset/val\");\n",
    "if(not os.path.isdir(\"dataset/test\")):\n",
    "    os.mkdir(\"dataset/test\");\n",
    "if(not os.path.isdir(\"dataset/train/images\")):\n",
    "    os.mkdir(\"dataset/train/images\");\n",
    "if(not os.path.isdir(\"dataset/train/annos\")):\n",
    "    os.mkdir(\"dataset/train/annos\");\n",
    "if(not os.path.isdir(\"dataset/val/images\")):\n",
    "    os.mkdir(\"dataset/val/images\");\n",
    "if(not os.path.isdir(\"dataset/val/annos\")):\n",
    "    os.mkdir(\"dataset/val/annos\");\n",
    "if(not os.path.isdir(\"dataset/test/images\")):\n",
    "    os.mkdir(\"dataset/test/images\");\n",
    "if(not os.path.isdir(\"dataset/test/annos\")):\n",
    "    os.mkdir(\"dataset/test/annos\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"wild\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"wild/ImageSets/Main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "f = open(\"wild/ImageSets/Main/train.txt\", 'r');\n",
    "lines = f.readlines();\n",
    "f.close();\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(lines))):\n",
    "    cmd1 = \"cp wild/JPEGImages/\" + lines[i][:len(lines[i])-1] + \".jpg dataset/train/images/\";\n",
    "    cmd2 = \"cp wild/Annotations/\" + lines[i][:len(lines[i])-1] + \".xml dataset/train/annos/\";\n",
    "    \n",
    "    #print(cmd1);\n",
    "    #print(cmd2);\n",
    "    \n",
    "    os.system(cmd1);\n",
    "    os.system(cmd2);\n",
    "    \n",
    "    #break;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "f = open(\"wild/ImageSets/Main/val.txt\", 'r');\n",
    "lines = f.readlines();\n",
    "f.close();\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(lines))):\n",
    "    cmd1 = \"cp wild/JPEGImages/\" + lines[i][:len(lines[i])-1] + \".jpg dataset/val/images/\";\n",
    "    cmd2 = \"cp wild/Annotations/\" + lines[i][:len(lines[i])-1] + \".xml dataset/val/annos/\";\n",
    "    \n",
    "    #print(cmd1);\n",
    "    #print(cmd2);\n",
    "    \n",
    "    os.system(cmd1);\n",
    "    os.system(cmd2);\n",
    "    \n",
    "    #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "f = open(\"wild/ImageSets/Main/test.txt\", 'r');\n",
    "lines = f.readlines();\n",
    "f.close();\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(lines))):\n",
    "    cmd1 = \"cp wild/JPEGImages/\" + lines[i][:len(lines[i])-1] + \".jpg dataset/test/images/\";\n",
    "    cmd2 = \"cp wild/Annotations/\" + lines[i][:len(lines[i])-1] + \".xml dataset/test/annos/\";\n",
    "    \n",
    "    #print(cmd1);\n",
    "    #print(cmd2);\n",
    "    \n",
    "    os.system(cmd1);\n",
    "    os.system(cmd2);\n",
    "    \n",
    "    #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOC to coco type - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xmltodict\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "root_dir = \"dataset/train/\";\n",
    "img_dir = \"images/\";\n",
    "anno_dir = \"annos/\";\n",
    "\n",
    "files = os.listdir(root_dir + anno_dir);\n",
    "\n",
    "combined = [];\n",
    "for i in tqdm(range(len(files))):\n",
    "    annoFile = root_dir + \"/\" + anno_dir + \"/\" + files[i];\n",
    "    f = open(annoFile, 'r');\n",
    "    my_xml = f.read();\n",
    "    anno = dict(dict(xmltodict.parse(my_xml))[\"annotation\"])\n",
    "    fname = anno[\"filename\"];\n",
    "    label_str = \"\";\n",
    "    if(type(anno[\"object\"]) == list):\n",
    "        for j in range(len(anno[\"object\"])):\n",
    "            obj = dict(anno[\"object\"][j]);\n",
    "            label = anno[\"object\"][j][\"name\"];\n",
    "            bbox = dict(anno[\"object\"][j][\"bndbox\"])\n",
    "            x1 = bbox[\"xmin\"];\n",
    "            y1 = bbox[\"ymin\"];\n",
    "            x2 = bbox[\"xmax\"];\n",
    "            y2 = bbox[\"ymax\"];\n",
    "            if(j == len(anno[\"object\"])-1):\n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "            else:        \n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n",
    "    else:\n",
    "        obj = dict(anno[\"object\"]);\n",
    "        label = anno[\"object\"][\"name\"];\n",
    "        bbox = dict(anno[\"object\"][\"bndbox\"])\n",
    "        x1 = bbox[\"xmin\"];\n",
    "        y1 = bbox[\"ymin\"];\n",
    "        x2 = bbox[\"xmax\"];\n",
    "        y2 = bbox[\"ymax\"];\n",
    "        \n",
    "        label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "    \n",
    "    \n",
    "    combined.append([fname, label_str])\n",
    "    \n",
    "df = pd.DataFrame(combined, columns = ['ID', 'Label']);\n",
    "df.to_csv(root_dir + \"/train_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install dicttoxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import dicttoxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import parseString\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "root = \"dataset/train/\";\n",
    "img_dir = \"images/\";\n",
    "anno_file = \"train_labels.csv\";\n",
    "\n",
    "dataset_path = root;\n",
    "images_folder = root + \"/\" + img_dir;\n",
    "annotations_path = root + \"/annotations/\";\n",
    "\n",
    "if not os.path.isdir(annotations_path):\n",
    "    os.mkdir(annotations_path)\n",
    "    \n",
    "input_images_folder = images_folder;\n",
    "input_annotations_path = root + \"/\" + anno_file;\n",
    "\n",
    "output_dataset_path = root;\n",
    "output_image_folder = input_images_folder;\n",
    "output_annotation_folder = annotations_path;\n",
    "\n",
    "tmp = img_dir.replace(\"/\", \"\");\n",
    "output_annotation_file = output_annotation_folder + \"/instances_\" + tmp + \".json\";\n",
    "output_classes_file = output_annotation_folder + \"/classes.txt\";\n",
    "\n",
    "\n",
    "if not os.path.isdir(output_annotation_folder):\n",
    "    os.mkdir(output_annotation_folder);\n",
    "\n",
    "df = pd.read_csv(input_annotations_path);\n",
    "columns = df.columns\n",
    "\n",
    "delimiter = \" \";\n",
    "\n",
    "list_dict = [];\n",
    "anno = [];\n",
    "for i in range(len(df)):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    for j in range(len(tmp)//5):\n",
    "        label = tmp[j*5+4];\n",
    "        if(label not in anno):\n",
    "            anno.append(label);\n",
    "    anno = sorted(anno)\n",
    "    \n",
    "for i in tqdm(range(len(anno))):\n",
    "    tmp = {};\n",
    "    tmp[\"supercategory\"] = \"master\";\n",
    "    tmp[\"id\"] = i;\n",
    "    tmp[\"name\"] = anno[i];\n",
    "    list_dict.append(tmp);\n",
    "\n",
    "anno_f = open(output_classes_file, 'w');\n",
    "for i in range(len(anno)):\n",
    "    anno_f.write(anno[i] + \"\\n\");\n",
    "anno_f.close();\n",
    "\n",
    "coco_data = {};\n",
    "coco_data[\"type\"] = \"instances\";\n",
    "coco_data[\"images\"] = [];\n",
    "coco_data[\"annotations\"] = [];\n",
    "coco_data[\"categories\"] = list_dict;\n",
    "image_id = 0;\n",
    "annotation_id = 0;\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    image_in_path = input_images_folder + \"/\" + img_name;\n",
    "    #print(image_in_path)\n",
    "    img = cv2.imread(image_in_path, 1);\n",
    "    h, w, c = img.shape;\n",
    "\n",
    "    images_tmp = {};\n",
    "    images_tmp[\"file_name\"] = img_name;\n",
    "    images_tmp[\"height\"] = h;\n",
    "    images_tmp[\"width\"] = w;\n",
    "    images_tmp[\"id\"] = image_id;\n",
    "    coco_data[\"images\"].append(images_tmp);\n",
    "    \n",
    "\n",
    "    for j in range(len(tmp)//5):\n",
    "        x1 = int(tmp[j*5+0]);\n",
    "        y1 = int(tmp[j*5+1]);\n",
    "        x2 = int(tmp[j*5+2]);\n",
    "        y2 = int(tmp[j*5+3]);\n",
    "        label = tmp[j*5+4];\n",
    "        annotations_tmp = {};\n",
    "        annotations_tmp[\"id\"] = annotation_id;\n",
    "        annotation_id += 1;\n",
    "        annotations_tmp[\"image_id\"] = image_id;\n",
    "        annotations_tmp[\"segmentation\"] = [];\n",
    "        annotations_tmp[\"ignore\"] = 0;\n",
    "        annotations_tmp[\"area\"] = (x2-x1)*(y2-y1);\n",
    "        annotations_tmp[\"iscrowd\"] = 0;\n",
    "        annotations_tmp[\"bbox\"] = [x1, y1, x2-x1, y2-y1];\n",
    "        annotations_tmp[\"category_id\"] = anno.index(label);\n",
    "\n",
    "        coco_data[\"annotations\"].append(annotations_tmp)\n",
    "    image_id += 1;\n",
    "\n",
    "outfile =  open(output_annotation_file, 'w');\n",
    "json_str = json.dumps(coco_data, indent=4);\n",
    "outfile.write(json_str);\n",
    "outfile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOC to coco type - Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xmltodict\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "root_dir = \"dataset/val/\";\n",
    "img_dir = \"images/\";\n",
    "anno_dir = \"annos/\";\n",
    "\n",
    "files = os.listdir(root_dir + anno_dir);\n",
    "\n",
    "combined = [];\n",
    "for i in tqdm(range(len(files))):\n",
    "    annoFile = root_dir + \"/\" + anno_dir + \"/\" + files[i];\n",
    "    f = open(annoFile, 'r');\n",
    "    my_xml = f.read();\n",
    "    anno = dict(dict(xmltodict.parse(my_xml))[\"annotation\"])\n",
    "    fname = anno[\"filename\"];\n",
    "    label_str = \"\";\n",
    "    if(type(anno[\"object\"]) == list):\n",
    "        for j in range(len(anno[\"object\"])):\n",
    "            obj = dict(anno[\"object\"][j]);\n",
    "            label = anno[\"object\"][j][\"name\"];\n",
    "            bbox = dict(anno[\"object\"][j][\"bndbox\"])\n",
    "            x1 = bbox[\"xmin\"];\n",
    "            y1 = bbox[\"ymin\"];\n",
    "            x2 = bbox[\"xmax\"];\n",
    "            y2 = bbox[\"ymax\"];\n",
    "            if(j == len(anno[\"object\"])-1):\n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "            else:        \n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n",
    "    else:\n",
    "        obj = dict(anno[\"object\"]);\n",
    "        label = anno[\"object\"][\"name\"];\n",
    "        bbox = dict(anno[\"object\"][\"bndbox\"])\n",
    "        x1 = bbox[\"xmin\"];\n",
    "        y1 = bbox[\"ymin\"];\n",
    "        x2 = bbox[\"xmax\"];\n",
    "        y2 = bbox[\"ymax\"];\n",
    "        \n",
    "        label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "    \n",
    "    \n",
    "    combined.append([fname, label_str])\n",
    "    \n",
    "df = pd.DataFrame(combined, columns = ['ID', 'Label']);\n",
    "df.to_csv(root_dir + \"/train_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import dicttoxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import parseString\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "root = \"dataset/val/\";\n",
    "img_dir = \"images/\";\n",
    "anno_file = \"train_labels.csv\";\n",
    "\n",
    "dataset_path = root;\n",
    "images_folder = root + \"/\" + img_dir;\n",
    "annotations_path = root + \"/annotations/\";\n",
    "\n",
    "if not os.path.isdir(annotations_path):\n",
    "    os.mkdir(annotations_path)\n",
    "    \n",
    "input_images_folder = images_folder;\n",
    "input_annotations_path = root + \"/\" + anno_file;\n",
    "\n",
    "output_dataset_path = root;\n",
    "output_image_folder = input_images_folder;\n",
    "output_annotation_folder = annotations_path;\n",
    "\n",
    "tmp = img_dir.replace(\"/\", \"\");\n",
    "output_annotation_file = output_annotation_folder + \"/instances_\" + tmp + \".json\";\n",
    "output_classes_file = output_annotation_folder + \"/classes.txt\";\n",
    "\n",
    "\n",
    "if not os.path.isdir(output_annotation_folder):\n",
    "    os.mkdir(output_annotation_folder);\n",
    "\n",
    "df = pd.read_csv(input_annotations_path);\n",
    "columns = df.columns\n",
    "\n",
    "delimiter = \" \";\n",
    "\n",
    "list_dict = [];\n",
    "anno = [];\n",
    "for i in range(len(df)):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    for j in range(len(tmp)//5):\n",
    "        label = tmp[j*5+4];\n",
    "        if(label not in anno):\n",
    "            anno.append(label);\n",
    "    anno = sorted(anno)\n",
    "    \n",
    "for i in tqdm(range(len(anno))):\n",
    "    tmp = {};\n",
    "    tmp[\"supercategory\"] = \"master\";\n",
    "    tmp[\"id\"] = i;\n",
    "    tmp[\"name\"] = anno[i];\n",
    "    list_dict.append(tmp);\n",
    "\n",
    "anno_f = open(output_classes_file, 'w');\n",
    "for i in range(len(anno)):\n",
    "    anno_f.write(anno[i] + \"\\n\");\n",
    "anno_f.close();\n",
    "\n",
    "coco_data = {};\n",
    "coco_data[\"type\"] = \"instances\";\n",
    "coco_data[\"images\"] = [];\n",
    "coco_data[\"annotations\"] = [];\n",
    "coco_data[\"categories\"] = list_dict;\n",
    "image_id = 0;\n",
    "annotation_id = 0;\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    image_in_path = input_images_folder + \"/\" + img_name;\n",
    "    #print(image_in_path)\n",
    "    img = cv2.imread(image_in_path, 1);\n",
    "    h, w, c = img.shape;\n",
    "\n",
    "    images_tmp = {};\n",
    "    images_tmp[\"file_name\"] = img_name;\n",
    "    images_tmp[\"height\"] = h;\n",
    "    images_tmp[\"width\"] = w;\n",
    "    images_tmp[\"id\"] = image_id;\n",
    "    coco_data[\"images\"].append(images_tmp);\n",
    "    \n",
    "\n",
    "    for j in range(len(tmp)//5):\n",
    "        x1 = int(tmp[j*5+0]);\n",
    "        y1 = int(tmp[j*5+1]);\n",
    "        x2 = int(tmp[j*5+2]);\n",
    "        y2 = int(tmp[j*5+3]);\n",
    "        label = tmp[j*5+4];\n",
    "        annotations_tmp = {};\n",
    "        annotations_tmp[\"id\"] = annotation_id;\n",
    "        annotation_id += 1;\n",
    "        annotations_tmp[\"image_id\"] = image_id;\n",
    "        annotations_tmp[\"segmentation\"] = [];\n",
    "        annotations_tmp[\"ignore\"] = 0;\n",
    "        annotations_tmp[\"area\"] = (x2-x1)*(y2-y1);\n",
    "        annotations_tmp[\"iscrowd\"] = 0;\n",
    "        annotations_tmp[\"bbox\"] = [x1, y1, x2-x1, y2-y1];\n",
    "        annotations_tmp[\"category_id\"] = anno.index(label);\n",
    "\n",
    "        coco_data[\"annotations\"].append(annotations_tmp)\n",
    "    image_id += 1;\n",
    "\n",
    "outfile =  open(output_annotation_file, 'w');\n",
    "json_str = json.dumps(coco_data, indent=4);\n",
    "outfile.write(json_str);\n",
    "outfile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOC to COCO Type - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xmltodict\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "root_dir = \"dataset/test/\";\n",
    "img_dir = \"images/\";\n",
    "anno_dir = \"annos/\";\n",
    "\n",
    "files = os.listdir(root_dir + anno_dir);\n",
    "\n",
    "combined = [];\n",
    "for i in tqdm(range(len(files))):\n",
    "    annoFile = root_dir + \"/\" + anno_dir + \"/\" + files[i];\n",
    "    f = open(annoFile, 'r');\n",
    "    my_xml = f.read();\n",
    "    anno = dict(dict(xmltodict.parse(my_xml))[\"annotation\"])\n",
    "    fname = anno[\"filename\"];\n",
    "    label_str = \"\";\n",
    "    if(type(anno[\"object\"]) == list):\n",
    "        for j in range(len(anno[\"object\"])):\n",
    "            obj = dict(anno[\"object\"][j]);\n",
    "            label = anno[\"object\"][j][\"name\"];\n",
    "            bbox = dict(anno[\"object\"][j][\"bndbox\"])\n",
    "            x1 = bbox[\"xmin\"];\n",
    "            y1 = bbox[\"ymin\"];\n",
    "            x2 = bbox[\"xmax\"];\n",
    "            y2 = bbox[\"ymax\"];\n",
    "            if(j == len(anno[\"object\"])-1):\n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "            else:        \n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n",
    "    else:\n",
    "        obj = dict(anno[\"object\"]);\n",
    "        label = anno[\"object\"][\"name\"];\n",
    "        bbox = dict(anno[\"object\"][\"bndbox\"])\n",
    "        x1 = bbox[\"xmin\"];\n",
    "        y1 = bbox[\"ymin\"];\n",
    "        x2 = bbox[\"xmax\"];\n",
    "        y2 = bbox[\"ymax\"];\n",
    "        \n",
    "        label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "    \n",
    "    \n",
    "    combined.append([fname, label_str])\n",
    "    \n",
    "df = pd.DataFrame(combined, columns = ['ID', 'Label']);\n",
    "df.to_csv(root_dir + \"/train_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import dicttoxml\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import parseString\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "root = \"dataset/test/\";\n",
    "img_dir = \"images/\";\n",
    "anno_file = \"train_labels.csv\";\n",
    "\n",
    "dataset_path = root;\n",
    "images_folder = root + \"/\" + img_dir;\n",
    "annotations_path = root + \"/annotations/\";\n",
    "\n",
    "if not os.path.isdir(annotations_path):\n",
    "    os.mkdir(annotations_path)\n",
    "    \n",
    "input_images_folder = images_folder;\n",
    "input_annotations_path = root + \"/\" + anno_file;\n",
    "\n",
    "output_dataset_path = root;\n",
    "output_image_folder = input_images_folder;\n",
    "output_annotation_folder = annotations_path;\n",
    "\n",
    "tmp = img_dir.replace(\"/\", \"\");\n",
    "output_annotation_file = output_annotation_folder + \"/instances_\" + tmp + \".json\";\n",
    "output_classes_file = output_annotation_folder + \"/classes.txt\";\n",
    "\n",
    "\n",
    "if not os.path.isdir(output_annotation_folder):\n",
    "    os.mkdir(output_annotation_folder);\n",
    "\n",
    "df = pd.read_csv(input_annotations_path);\n",
    "columns = df.columns\n",
    "\n",
    "delimiter = \" \";\n",
    "\n",
    "list_dict = [];\n",
    "anno = [];\n",
    "for i in range(len(df)):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    for j in range(len(tmp)//5):\n",
    "        label = tmp[j*5+4];\n",
    "        if(label not in anno):\n",
    "            anno.append(label);\n",
    "    anno = sorted(anno)\n",
    "    \n",
    "for i in tqdm(range(len(anno))):\n",
    "    tmp = {};\n",
    "    tmp[\"supercategory\"] = \"master\";\n",
    "    tmp[\"id\"] = i;\n",
    "    tmp[\"name\"] = anno[i];\n",
    "    list_dict.append(tmp);\n",
    "\n",
    "anno_f = open(output_classes_file, 'w');\n",
    "for i in range(len(anno)):\n",
    "    anno_f.write(anno[i] + \"\\n\");\n",
    "anno_f.close();\n",
    "\n",
    "coco_data = {};\n",
    "coco_data[\"type\"] = \"instances\";\n",
    "coco_data[\"images\"] = [];\n",
    "coco_data[\"annotations\"] = [];\n",
    "coco_data[\"categories\"] = list_dict;\n",
    "image_id = 0;\n",
    "annotation_id = 0;\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_name = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(delimiter);\n",
    "    image_in_path = input_images_folder + \"/\" + img_name;\n",
    "    #print(image_in_path)\n",
    "    img = cv2.imread(image_in_path, 1);\n",
    "    h, w, c = img.shape;\n",
    "\n",
    "    images_tmp = {};\n",
    "    images_tmp[\"file_name\"] = img_name;\n",
    "    images_tmp[\"height\"] = h;\n",
    "    images_tmp[\"width\"] = w;\n",
    "    images_tmp[\"id\"] = image_id;\n",
    "    coco_data[\"images\"].append(images_tmp);\n",
    "    \n",
    "\n",
    "    for j in range(len(tmp)//5):\n",
    "        x1 = int(tmp[j*5+0]);\n",
    "        y1 = int(tmp[j*5+1]);\n",
    "        x2 = int(tmp[j*5+2]);\n",
    "        y2 = int(tmp[j*5+3]);\n",
    "        label = tmp[j*5+4];\n",
    "        annotations_tmp = {};\n",
    "        annotations_tmp[\"id\"] = annotation_id;\n",
    "        annotation_id += 1;\n",
    "        annotations_tmp[\"image_id\"] = image_id;\n",
    "        annotations_tmp[\"segmentation\"] = [];\n",
    "        annotations_tmp[\"ignore\"] = 0;\n",
    "        annotations_tmp[\"area\"] = (x2-x1)*(y2-y1);\n",
    "        annotations_tmp[\"iscrowd\"] = 0;\n",
    "        annotations_tmp[\"bbox\"] = [x1, y1, x2-x1, y2-y1];\n",
    "        annotations_tmp[\"category_id\"] = anno.index(label);\n",
    "\n",
    "        coco_data[\"annotations\"].append(annotations_tmp)\n",
    "    image_id += 1;\n",
    "\n",
    "outfile =  open(output_annotation_file, 'w');\n",
    "json_str = json.dumps(coco_data, indent=4);\n",
    "outfile.write(json_str);\n",
    "outfile.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/10_pytorch_efficientdet/lib/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_detector import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Detector();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dataset/train/annotations/classes.txt\", 'r');\n",
    "classes_list = f.readlines();\n",
    "f.close();\n",
    "\n",
    "for i in range(len(classes_list)):\n",
    "    classes_list[i] = classes_list[i][:len(classes_list[i])-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"dataset/\";\n",
    "coco_dir = \"train/\";\n",
    "img_dir = \"\";\n",
    "set_dir = \"images\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.set_train_dataset(root_dir, coco_dir, img_dir, set_dir, classes_list=classes_list, batch_size=2, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"dataset/\";\n",
    "coco_dir = \"val/\";\n",
    "img_dir = \"\";\n",
    "set_dir = \"images\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.set_val_dataset(root_dir, coco_dir, img_dir, set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Available models\n",
    "\"efficientdet-d0.pth\"\n",
    "\"efficientdet-d1.pth\"\n",
    "\"efficientdet-d2.pth\"\n",
    "\"efficientdet-d3.pth\"\n",
    "\"efficientdet-d4.pth\"\n",
    "\"efficientdet-d5.pth\"\n",
    "\"efficientdet-d6.pth\"\n",
    "\"efficientdet-d7.pth\"\n",
    "\n",
    "gtf.set_model(model_name=\"efficientdet-d3.pth\", num_gpus=1, freeze_head=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Available optimizers\n",
    "#adamw\n",
    "#sgd\n",
    "\n",
    "gtf.set_hyperparams(optimizer=\"adamw\", lr=0.001, es_min_delta=0.0, es_patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.train(num_epochs=20, val_interval=1, save_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/10_pytorch_efficientdet/lib/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_detector import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dataset/train/annotations/classes.txt\", 'r');\n",
    "classes_list = f.readlines();\n",
    "f.close();\n",
    "\n",
    "for i in range(len(classes_list)):\n",
    "    classes_list[i] = classes_list[i][:len(classes_list[i])-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"trained_weights/custom/efficientdet-d3_trained.pth\";\n",
    "gtf.load_model(model_path, classes_list, use_gpu=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = os.listdir(\"dataset/test/images/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"dataset/test/images/\" + img_list[20], threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"dataset/test/images/\" + img_list[30], threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"dataset/test/images/\" + img_list[41], threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"dataset/test/images/\" + img_list[51], threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.predict(\"dataset/test/images/\" + img_list[90], threshold=0.8);\n",
    "from IPython.display import Image\n",
    "Image(filename='output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
