{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20Document%20Layout%20Analysis%20(SSD512).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Layout Analysis Using SSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the network:\n",
    "1. Paper on SSD: https://arxiv.org/abs/1512.02325\n",
    "\n",
    "2. Blog-1 on SSD: https://towardsdatascience.com/review-ssd-single-shot-detector-object-detection-851a94607d11\n",
    "\n",
    "3. Blog-2 on SSD: https://medium.com/@jonathan_hui/ssd-object-detection-single-shot-multibox-detector-for-real-time-processing-9bd8deac0e06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "### 1. Installation Instructions\n",
    "### 2. Use trained Model for Document Layout Analysis\n",
    "### 3. How to train using PRImA Layout Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "- Run these commands\n",
    "\n",
    "    - git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n",
    "\n",
    "    - cd Monk_Object_Detection/1_gluoncv_finetune/installation\n",
    "\n",
    "- Select the right requirements file and run\n",
    "\n",
    "    - cat requirements_cuda10.1.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colab use the command below\n",
    "#! cd Monk_Object_Detection/1_gluoncv_finetune/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install\n",
    "\n",
    "\n",
    "# For Local systems and cloud select the right CUDA version\n",
    "!cd Monk_Object_Detection/1_gluoncv_finetune/installation && cat requirements_cuda10.1.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Already Trained Model for Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/1_gluoncv_finetune/lib/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_prototype import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1E6T7RKGwy-v1MUxVJm-rxt5XcRyr2SQ7' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1E6T7RKGwy-v1MUxVJm-rxt5XcRyr2SQ7\" -O obj_dla_ssd512_trained.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq obj_dla_ssd512_trained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ssd_512_vgg16_atrous_coco\";\n",
    "params_file = \"dla_ssd512/dla_ssd512-vgg16.params\";\n",
    "class_list = [\"paragraph\", \"heading\", \"credit\", \"footer\", \"drop-capital\", \"floating\", \"noise\", \"maths\", \"header\", \"caption\", \"image\", \"linedrawing\", \"graphics\", \"fname\", \"page-number\", \"chart\", \"separator\", \"table\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer(model_name, params_file, class_list, use_gpu=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test_Images/test1.jpg\"; \n",
    "visualize = True;\n",
    "thresh = 0.3;\n",
    "output = gtf.run(img_name, visualize=visualize, thresh=thresh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test_Images/test2.jpg\"; \n",
    "visualize = True;\n",
    "thresh = 0.3;\n",
    "output = gtf.run(img_name, visualize=visualize, thresh=thresh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test_Images/test3.jpg\"; \n",
    "visualize = True;\n",
    "thresh = 0.4;\n",
    "output = gtf.run(img_name, visualize=visualize, thresh=thresh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Your Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Credits\n",
    "- https://www.primaresearch.org/datasets/Layout_Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1iBfafT1WHAtKAW0a1ifLzvW5f0ytm2i_' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1iBfafT1WHAtKAW0a1ifLzvW5f0ytm2i_\" -O PRImA_Layout_Analysis_Dataset.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq PRImA_Layout_Analysis_Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library for Data Augmentation\n",
    "Refer to https://github.com/albumentations-team/albumentations for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import xmltodict\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"PRImA Layout Analysis Dataset/\";\n",
    "img_dir = \"Images/\";\n",
    "anno_dir = \"XML/\";\n",
    "final_root_dir=\"Document_Layout_Analysis/\" #Directory for jpeg and augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(final_root_dir):\n",
    "    os.makedirs(final_root_dir)\n",
    "\n",
    "if not os.path.exists(final_root_dir+img_dir):\n",
    "    os.makedirs(final_root_dir+img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIFF Image Format to JPEG Image Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in glob.glob(root_dir+img_dir+'*.tif'):\n",
    "    im = Image.open(name)\n",
    "    name = str(name).rstrip(\".tif\")\n",
    "    name = str(name).lstrip(root_dir)\n",
    "    name = str(name).lstrip(img_dir)\n",
    "    im.save(final_root_dir+ img_dir+ name + '.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Conversion and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given format- VOC Format\n",
    "\n",
    "### Dataset Directory Structure\n",
    "\n",
    "    ./PRImA Layout Analysis Dataset/ (root_dir)\n",
    "          |\n",
    "          |-----------Images (img_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.jpg\n",
    "          |              |------------------img2.jpg\n",
    "          |              |------------------.........(and so on)\n",
    "          |\n",
    "          |\n",
    "          |-----------Annotations (anno_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.xml\n",
    "          |              |------------------img2.xml\n",
    "          |              |------------------.........(and so on)\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Format- Monk Format\n",
    "\n",
    "### Dataset Directory Structure\n",
    "\n",
    "    ./Document_Layout_Analysis/ (final_root_dir)\n",
    "          |\n",
    "          |-----------Images (img_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.jpg\n",
    "          |              |------------------img2.jpg\n",
    "          |              |------------------.........(and so on)\n",
    "          |\n",
    "          |\n",
    "          |-----------train_labels.csv (anno_file)\n",
    "          \n",
    "          \n",
    "### Annotation file format\n",
    "\n",
    "           | Id         | Labels                                 |\n",
    "           | img1.jpg   | x1 y1 x2 y2 label1 x1 y1 x2 y2 label2  |\n",
    "           \n",
    "- Labels:  xmin ymin xmax ymax label\n",
    "- xmin, ymin - top left corner of bounding box\n",
    "- xmax, ymax - bottom right corner of bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(root_dir + anno_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentData(fname, boxes):\n",
    "    image = cv2.imread(final_root_dir+img_dir+fname)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    transform = A.Compose([\n",
    "        A.IAAPerspective(p=0.7),   \n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=5, p=0.5),\n",
    "        A.IAAAdditiveGaussianNoise(),\n",
    "        A.ChannelShuffle(),\n",
    "        A.RandomBrightnessContrast(),\n",
    "        A.RGBShift(p=0.8),\n",
    "        A.HueSaturationValue(p=0.8)\n",
    "        ], bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.2))\n",
    "    \n",
    "    for i in range(1, 9):\n",
    "        label=\"\"\n",
    "        transformed = transform(image=image, bboxes=boxes)\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_bboxes = transformed['bboxes']\n",
    "        #print(transformed_bboxes)\n",
    "        flag=False\n",
    "        for box in transformed_bboxes:\n",
    "            x_min, y_min, x_max, y_max, class_name = box\n",
    "            if(xmax<=xmin or ymax<=ymin):\n",
    "                flag=True\n",
    "                break\n",
    "            label+= str(int(x_min))+' '+str(int(y_min))+' '+str(int(x_max))+' '+str(int(y_max))+' '+class_name+' '\n",
    "                        \n",
    "        if(flag):\n",
    "            continue\n",
    "        cv2.imwrite(final_root_dir+img_dir+str(i)+fname, transformed_image)\n",
    "        label=label[:-1]\n",
    "        combined.append([str(i) + fname, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOC to Monk Format Conversion\n",
    "Applying Data Augmentation only on those images which contain atleast 1 minority class so as to reduce bias in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#label generation for csv\n",
    "for i in tqdm(range(len(files))):\n",
    "    box=[];\n",
    "    augment=False;\n",
    "    annoFile = root_dir + anno_dir + files[i];\n",
    "    f = open(annoFile, 'r');\n",
    "    my_xml = f.read();\n",
    "    anno= dict(dict(dict(xmltodict.parse(my_xml))['PcGts'])['Page'])\n",
    "    fname=\"\"\n",
    "    for j in range(len(files[i])):\n",
    "        if((files[i][j])>='0' and files[i][j]<='9'):\n",
    "            fname+=files[i][j];\n",
    "    fname+=\".jpg\"\n",
    "    image = cv2.imread(final_root_dir+img_dir+fname)\n",
    "    height, width = image.shape[:2]    \n",
    "    label_str = \"\"\n",
    "    for key in anno.keys():\n",
    "        if(key=='@imageFilename' or key=='@imageWidth' or key=='@imageHeight'):\n",
    "            continue\n",
    "        if(key==\"TextRegion\"):\n",
    "            if(type(anno[\"TextRegion\"]) == list):\n",
    "                for j in range(len(anno[\"TextRegion\"])):\n",
    "                    text=anno[\"TextRegion\"][j]\n",
    "                    xmin=width\n",
    "                    ymin=height\n",
    "                    xmax=0\n",
    "                    ymax=0\n",
    "                    if(text[\"Coords\"]):\n",
    "                        if(text[\"Coords\"][\"Point\"]):\n",
    "                            for k in range(len(text[\"Coords\"][\"Point\"])):\n",
    "                                coordinates=anno[\"TextRegion\"][j][\"Coords\"][\"Point\"][k]\n",
    "                                xmin= min(xmin, int(coordinates['@x']));\n",
    "                                ymin= min(ymin, int(coordinates['@y']));\n",
    "                                xmax= min(max(xmax, int(coordinates['@x'])), width);\n",
    "                                ymax= min(max(ymax, int(coordinates['@y'])), height);\n",
    "                            if('@type' in text.keys()):    \n",
    "                                label_str+= str(xmin)+' '+str(ymin)+' '+str(xmax)+' '+str(ymax)+' '+text['@type']+' '\n",
    "                                if(xmax<=xmin or ymax<=ymin):\n",
    "                                    continue\n",
    "                                tbox=[];\n",
    "                                tbox.append(xmin)\n",
    "                                tbox.append(ymin)\n",
    "                                tbox.append(xmax)\n",
    "                                tbox.append(ymax)\n",
    "                                tbox.append(text['@type'])\n",
    "                                box.append(tbox)\n",
    "            else:\n",
    "                text=anno[\"TextRegion\"]\n",
    "                xmin=width\n",
    "                ymin=height\n",
    "                xmax=0\n",
    "                ymax=0\n",
    "                if(text[\"Coords\"]):\n",
    "                    if(text[\"Coords\"][\"Point\"]):\n",
    "                        for k in range(len(text[\"Coords\"][\"Point\"])):\n",
    "                            coordinates=anno[\"TextRegion\"][\"Coords\"][\"Point\"][k]\n",
    "                            xmin= min(xmin, int(coordinates['@x']));\n",
    "                            ymin= min(ymin, int(coordinates['@y']));\n",
    "                            xmax= min(max(xmax, int(coordinates['@x'])), width);\n",
    "                            ymax= min(max(ymax, int(coordinates['@y'])), height);\n",
    "                        if('@type' in text.keys()):    \n",
    "                            label_str+= str(xmin)+' '+str(ymin)+' '+str(xmax)+' '+str(ymax)+' '+text['@type']+' '\n",
    "                            if(xmax<=xmin or ymax<=ymin):\n",
    "                                continue\n",
    "                            tbox=[];\n",
    "                            tbox.append(xmin)\n",
    "                            tbox.append(ymin)\n",
    "                            tbox.append(xmax)\n",
    "                            tbox.append(ymax)\n",
    "                            tbox.append(text['@type'])\n",
    "                            box.append(tbox)\n",
    "        \n",
    "        else:\n",
    "            val=\"\"\n",
    "            if(key=='GraphicRegion'):\n",
    "                val=\"graphics\"\n",
    "                augment=True\n",
    "            elif(key=='ImageRegion'):\n",
    "                val=\"image\"\n",
    "            elif(key=='NoiseRegion'):\n",
    "                val=\"noise\"\n",
    "                augment=True\n",
    "            elif(key=='ChartRegion'):\n",
    "                val=\"chart\"\n",
    "                augment=True\n",
    "            elif(key=='TableRegion'):\n",
    "                val=\"table\"\n",
    "                augment=True\n",
    "            elif(key=='SeparatorRegion'):\n",
    "                val=\"separator\"\n",
    "            elif(key=='MathsRegion'):\n",
    "                val=\"maths\"\n",
    "                augment=True\n",
    "            elif(key=='LineDrawingRegion'):\n",
    "                val=\"linedrawing\"\n",
    "                augment=True\n",
    "            else:\n",
    "                val=\"frame\"\n",
    "                augment=True\n",
    "\n",
    "            \n",
    "            if(type(anno[key]) == list):\n",
    "                for j in range(len(anno[key])):\n",
    "                    text=anno[key][j]\n",
    "                    xmin=width\n",
    "                    ymin=height\n",
    "                    xmax=0\n",
    "                    ymax=0\n",
    "                    if(text[\"Coords\"]):\n",
    "                        if(text[\"Coords\"][\"Point\"]):\n",
    "                            for k in range(len(text[\"Coords\"][\"Point\"])):\n",
    "                                coordinates=anno[key][j][\"Coords\"][\"Point\"][k]\n",
    "                                xmin= min(xmin, int(coordinates['@x']));\n",
    "                                ymin= min(ymin, int(coordinates['@y']));\n",
    "                                xmax= min(max(xmax, int(coordinates['@x'])), width);\n",
    "                                ymax= min(max(ymax, int(coordinates['@y'])), height);\n",
    "                        label_str+= str(xmin)+' '+str(ymin)+' '+str(xmax)+' '+str(ymax)+' '+ val +' '\n",
    "                        if(xmax<=xmin or ymax<=ymin):\n",
    "                            continue\n",
    "                        tbox=[];\n",
    "                        tbox.append(xmin)\n",
    "                        tbox.append(ymin)\n",
    "                        tbox.append(xmax)\n",
    "                        tbox.append(ymax)\n",
    "                        tbox.append(val)\n",
    "                        box.append(tbox)\n",
    "            else:\n",
    "                text=anno[key]\n",
    "                xmin=width\n",
    "                ymin=height\n",
    "                xmax=0\n",
    "                ymax=0\n",
    "                if(text[\"Coords\"]):\n",
    "                    if(text[\"Coords\"][\"Point\"]):\n",
    "                        for k in range(len(text[\"Coords\"][\"Point\"])):\n",
    "                            coordinates=anno[key][\"Coords\"][\"Point\"][k]\n",
    "                            xmin= min(xmin, int(coordinates['@x']));\n",
    "                            ymin= min(ymin, int(coordinates['@y']));\n",
    "                            xmax= min(max(xmax, int(coordinates['@x'])), width);\n",
    "                            ymax= min(max(ymax, int(coordinates['@y'])), height);  \n",
    "                        label_str+= str(xmin)+' '+str(ymin)+' '+str(xmax)+' '+str(ymax)+' '+val+' '\n",
    "                        if(xmax<=xmin or ymax<=ymin):\n",
    "                            continue\n",
    "                        tbox=[];\n",
    "                        tbox.append(xmin)\n",
    "                        tbox.append(ymin)\n",
    "                        tbox.append(xmax)\n",
    "                        tbox.append(ymax)\n",
    "                        tbox.append(val)\n",
    "                        box.append(tbox)\n",
    "\n",
    "    label_str=label_str[:-1]\n",
    "    combined.append([fname, label_str])\n",
    "\n",
    "    if(augment):\n",
    "        augmentData(fname, box)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(combined, columns = ['ID', 'Label']);\n",
    "df.to_csv(final_root_dir + \"/train_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"Monk_Object_Detection/1_gluoncv_finetune/lib/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detector_prototype import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Detector();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"Document_Layout_Analysis/\";\n",
    "img_dir = \"Images/\";\n",
    "anno_file = \"train_labels.csv\";\n",
    "batch_size=8;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Dataset(root, img_dir, anno_file, batch_size=batch_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available models\n",
    "    ssd_300_vgg16_atrous_coco\n",
    "    ssd_300_vgg16_atrous_voc\n",
    "    ssd_512_vgg16_atrous_coco\n",
    "    ssd_512_vgg16_atrous_voc\n",
    "    ssd_512_resnet50_v1_coco\n",
    "    ssd_512_resnet50_v1_voc\n",
    "    ssd_512_mobilenet1.0_voc\n",
    "    ssd_512_mobilenet1.0_coco\n",
    "    yolo3_darknet53_voc\n",
    "    yolo3_darknet53_coco\n",
    "    yolo3_mobilenet1.0_voc\n",
    "    yolo3_mobilenet1.0_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16 architecture, with atrous convolutions, pretrained on COCO dataset is used for this task\n",
    "pretrained = True;         \n",
    "gpu=True;\n",
    "model_name = \"ssd_512_vgg16_atrous_coco\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Model(model_name, use_pretrained=pretrained, use_gpu=gpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Set_Learning_Rate(0.003);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30;\n",
    "params_file = \"saved_model.params\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf.Train(epochs, params_file);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/1_gluoncv_finetune/lib/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_prototype import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ssd_512_vgg16_atrous_coco\";\n",
    "params_file = \"saved_model.params\";\n",
    "class_list = [\"paragraph\", \"heading\", \"credit\", \"footer\", \"drop-capital\", \"floating\", \"noise\", \"maths\", \"header\", \"caption\", \"image\", \"linedrawing\", \"graphics\", \"fname\", \"page-number\", \"chart\", \"separator\", \"table\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer(model_name, params_file, class_list, use_gpu=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test_Images/test1.jpg\"; \n",
    "visualize = True;\n",
    "thresh = 0.3;\n",
    "output = gtf.run(img_name, visualize=visualize, thresh=thresh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test_Images/test2.jpg\"; \n",
    "visualize = True;\n",
    "thresh = 0.3;\n",
    "output = gtf.run(img_name, visualize=visualize, thresh=thresh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"Test_Images/test3.jpg\"; \n",
    "visualize = True;\n",
    "thresh = 0.4;\n",
    "output = gtf.run(img_name, visualize=visualize, thresh=thresh);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is performing well in identifying objects with very high confidence but it is biased a lot towards paragraphs. Its performance can be improved by using bigger batch size, training for more epochs and more data augmentation techniques to reduce bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
