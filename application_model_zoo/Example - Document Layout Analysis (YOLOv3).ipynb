{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/Monk_Object_Detection/blob/master/application_model_zoo/Example%20-%20Document%20Layout%20Analysis%20(YOLOv3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Layout Analysis using YOLOv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the network:\n",
    "1. Paper on Yolov3: https://arxiv.org/abs/1804.02767\n",
    "\n",
    "2. Darknet: https://pjreddie.com/darknet/\n",
    "\n",
    "3. Blog-1 on yolo: https://machinethink.net/blog/object-detection-with-yolo/\n",
    "\n",
    "4. Blog-2 on yolo: https://medium.com/@jonathan_hui/real-time-object-detection-with-yolo-yolov2-28b1b93e2088\n",
    "\n",
    "5. Blog-3 on yolo: https://blog.ekbana.com/training-yolov2-in-a-custom-dataset-6fcf58f65fa2\n",
    "\n",
    "6. Blog-4 on yolo: https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b\n",
    "\n",
    "7. Blog-5 on yolo: https://blog.insightdatascience.com/how-to-train-your-own-yolov3-detector-from-scratch-224d10e55de2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "### 1. Installation Instructions\n",
    "### 2. Use trained Model for Document Layout Analysis\n",
    "### 3. How to train using PRImA Layout Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yolov3 pipeline of Monk Object Detection Library has been used for implementing this model. \n",
    "\n",
    "- Firstly, the dataset was converted to Yolo format. \n",
    "- The mode was trained for 10 epochs, with batch size=8, learning rate=0.005 and \"sgd\" optimizer (\"sgd\" performed better than \"adam\" optimizer). It achieved F1 score of 0.348 and mAP@0.5 of 0.318."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "- Run these commands\n",
    "\n",
    "    - git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n",
    "\n",
    "    - cd Monk_Object_Detection/7_yolov3/installation\n",
    "\n",
    "-Select the right requirements file and run\n",
    "    - cat requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colab use the command below\n",
    "#! cd Monk_Object_Detection/7_yolov3/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install\n",
    "\n",
    "# For Local systems and cloud select the right CUDA version\n",
    "! cd Monk_Object_Detection/7_yolov3/installation && cat requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Already Trained Model for Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import Image\n",
    "sys.path.append(\"Monk_Object_Detection/7_yolov3/lib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_detector import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Si1puABMiijtvLvH-XMnr2pVj4K2lUkO' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Si1puABMiijtvLvH-XMnr2pVj4K2lUkO\" -O obj_dla_yolov3_trained.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq obj_dla_yolov3_trained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv dla_yolov3/yolov3.cfg ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dla_yolov3/classes.txt\");\n",
    "class_list = f.readlines();\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"yolov3\";\n",
    "weights = \"dla_yolov3/dla_yolov3.pt\";\n",
    "gtf.Model(model_name, class_list, weights, use_gpu=True, input_size=416);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1VEkfJuicIr-STIqYOI-UruDDttWGXNxw' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1VEkfJuicIr-STIqYOI-UruDDttWGXNxw\" -O Test_Images.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq Test_Images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Test_Images/test1.jpg\";\n",
    "gtf.Predict(img_path, conf_thres=0.3, iou_thres=0.5);\n",
    "Image(filename='output/test1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Test_Images/test2.jpg\";\n",
    "gtf.Predict(img_path, conf_thres=0.25, iou_thres=0.5);\n",
    "Image(filename='output/test2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Test_Images/test3.jpg\";\n",
    "gtf.Predict(img_path, conf_thres=0.2, iou_thres=0.5);\n",
    "Image(filename='output/test3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Your Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Credits\n",
    "- https://www.primaresearch.org/datasets/Layout_Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1iBfafT1WHAtKAW0a1ifLzvW5f0ytm2i_' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1iBfafT1WHAtKAW0a1ifLzvW5f0ytm2i_\" -O PRImA_Layout_Analysis_Dataset.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -qq PRImA_Layout_Analysis_Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library for Data Augmentation\n",
    "Refer to https://github.com/albumentations-team/albumentations for more details\n",
    "\n",
    "\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "  - Normalisation: Calculated Mean & Standard deviation of training images (3 images taken out of dataset for inference) to feed into model for normalisation (used in FasterRCNN).\n",
    "\n",
    "  - Format Conversion: TIFF format was causing problems in data augmentation and training on TIFF images was more than 5x slower than JPEG format images because of their huge size. Therefore, TIFF images were converted to JPEG format images.\n",
    "\n",
    "  - Selective Data Augmentation: In the raw dataset 4750+ paragraph type objects and only 10-30 frames, graphics, etc. type objects which led to huge bias in dataset. To generate more data and to decrease bias, a customised function has been implemented from the scratch. This function produces random translational augmentated images of only those images which have minority classes in them. Using this function, the dataset size increased from 475 images to 1783 images. If data augmentation has been done on every image, there would have been 24000+ paragraphs in the dataset whereas there are 19568 now, which slightly improves the bias. (Exact numbers are in the data preprocessing notebook). The augmented images had to be saved in the dataset because augmentation function couldn't be called on the go.\n",
    "\n",
    "  - Conversion to VOC to Monk type- Coversion so that Monk format can be later used in SSD Model, converted to yolo type for Yolo model, and COCO format for FasterRCNN Model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import xmltodict\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"PRImA Layout Analysis Dataset/\";\n",
    "img_dir = \"Images/\";\n",
    "anno_dir = \"XML/\";\n",
    "final_root_dir=\"Document_Layout_Analysis/\" #Directory for jpeg and augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(final_root_dir):\n",
    "    os.makedirs(final_root_dir)\n",
    "\n",
    "if not os.path.exists(final_root_dir+img_dir):\n",
    "    os.makedirs(final_root_dir+img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIFF Image Format to JPEG Image Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in glob.glob(root_dir+img_dir+'*.tif'):\n",
    "    im = Image.open(name)\n",
    "    name = str(name).rstrip(\".tif\")\n",
    "    name = str(name).lstrip(root_dir)\n",
    "    name = str(name).lstrip(img_dir)\n",
    "    im.save(final_root_dir+ img_dir+ name + '.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Conversion and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As most part of a document is text, there were far more paragraphs in the dataset than there were other labels such as tables or graphs. To handle this huge bias in the dataset, we augmented only those document images which had one of these minority labels in them. For example, if the document only had paragraphs and images, then we didn’t augment it. But if it had tables, charts, graphs or any other minority label, we augmented that image by many folds. This process helped in reducing the bias in the dataset by around 25%. This selection and augmentation has been done during the format conversion from VOC to Monk Format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given format- VOC Format\n",
    "\n",
    "### Dataset Directory Structure\n",
    "\n",
    "    ./PRImA Layout Analysis Dataset/ (root_dir)\n",
    "          |\n",
    "          |-----------Images (img_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.jpg\n",
    "          |              |------------------img2.jpg\n",
    "          |              |------------------.........(and so on)\n",
    "          |\n",
    "          |\n",
    "          |-----------Annotations (anno_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.xml\n",
    "          |              |------------------img2.xml\n",
    "          |              |------------------.........(and so on)\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediatory Format- Monk Format\n",
    "\n",
    "### Dataset Directory Structure\n",
    "\n",
    "    ./Document_Layout_Analysis/ (final_root_dir)\n",
    "          |\n",
    "          |-----------Images (img_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.jpg\n",
    "          |              |------------------img2.jpg\n",
    "          |              |------------------.........(and so on)\n",
    "          |\n",
    "          |\n",
    "          |-----------train_labels.csv (anno_file)\n",
    "          \n",
    "          \n",
    "### Annotation file format\n",
    "\n",
    "           | Id         | Labels                                 |\n",
    "           | img1.jpg   | x1 y1 x2 y2 label1 x1 y1 x2 y2 label2  |\n",
    "           \n",
    "- Labels:  xmin ymin xmax ymax label\n",
    "- xmin, ymin - top left corner of bounding box\n",
    "- xmax, ymax - bottom right corner of bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Format - Yolo\n",
    "\n",
    "### Dataset Directory Structure\n",
    "\n",
    "        ./Document_Layout_Analysis/ (final_root_dir)\n",
    "          |\n",
    "          |-------------images (img_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.jpg\n",
    "          |              |------------------img2.jpg\n",
    "          |              |------------------.........(and so on)\n",
    "          |\n",
    "          |-----------labels (label_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.txt\n",
    "          |              |------------------img2.txt\n",
    "          |              |------------------.........(and so on)\n",
    "          |\n",
    "          |------------classes.txt \n",
    "          \n",
    "\n",
    "### Classes file\n",
    " \n",
    "     List of classes in every new line.\n",
    "     The order corresponds to the IDs in annotation files\n",
    "     \n",
    "     Eg.\n",
    "          class1               (------------------------------> if will be 0)\n",
    "          class2               (------------------------------> if will be 1)\n",
    "          class3               (------------------------------> if will be 2)\n",
    "          class4               (------------------------------> if will be 3)\n",
    "          \n",
    "\n",
    "### Annotation file format\n",
    "\n",
    "    CLASS_ID BOX_X_CENTER BOX_Y_CENTER WIDTH BOX_WIDTH BOX_HEIGHT\n",
    "    \n",
    "    (All the coordinates should be normalized)\n",
    "    (X coordinates divided by width of image, Y coordinates divided by height of image)\n",
    "    \n",
    "    Ex. (One line per bounding box of object in image)\n",
    "        class_id x1 y1 w h\n",
    "        class_id x1 y1 w h\n",
    "        ..... (and so on)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(root_dir + anno_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentData(fname, boxes):\n",
    "    image = cv2.imread(final_root_dir+img_dir+fname)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    transform = A.Compose([\n",
    "        A.IAAPerspective(p=0.7),   \n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=5, p=0.5),\n",
    "        A.IAAAdditiveGaussianNoise(),\n",
    "        A.ChannelShuffle(),\n",
    "        A.RandomBrightnessContrast(),\n",
    "        A.RGBShift(p=0.8),\n",
    "        A.HueSaturationValue(p=0.8)\n",
    "        ], bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.2))\n",
    "    \n",
    "    for i in range(1, 9):\n",
    "        label=\"\"\n",
    "        transformed = transform(image=image, bboxes=boxes)\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_bboxes = transformed['bboxes']\n",
    "        #print(transformed_bboxes)\n",
    "        flag=False\n",
    "        for box in transformed_bboxes:\n",
    "            x_min, y_min, x_max, y_max, class_name = box\n",
    "            if(xmax<=xmin or ymax<=ymin):\n",
    "                flag=True\n",
    "                break\n",
    "            label+= str(int(x_min))+' '+str(int(y_min))+' '+str(int(x_max))+' '+str(int(y_max))+' '+class_name+' '\n",
    "                        \n",
    "        if(flag):\n",
    "            continue\n",
    "        cv2.imwrite(final_root_dir+img_dir+str(i)+fname, transformed_image)\n",
    "        label=label[:-1]\n",
    "        combined.append([str(i) + fname, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOC to Monk Format Conversion\n",
    "Applying Data Augmentation only on those images which contain atleast 1 minority class so as to reduce bias in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#label generation for csv\n",
    "for i in tqdm(range(len(files))):\n",
    "    box=[];\n",
    "    augment=False;\n",
    "    annoFile = root_dir + anno_dir + files[i];\n",
    "    f = open(annoFile, 'r');\n",
    "    my_xml = f.read();\n",
    "    anno= dict(dict(dict(xmltodict.parse(my_xml))['PcGts'])['Page'])\n",
    "    fname=\"\"\n",
    "    for j in range(len(files[i])):\n",
    "        if((files[i][j])>='0' and files[i][j]<='9'):\n",
    "            fname+=files[i][j];\n",
    "    fname+=\".jpg\"\n",
    "    image = cv2.imread(final_root_dir+img_dir+fname)\n",
    "    height, width = image.shape[:2]    \n",
    "    label_str = \"\"\n",
    "    for key in anno.keys():\n",
    "        if(key=='@imageFilename' or key=='@imageWidth' or key=='@imageHeight'):\n",
    "            continue\n",
    "        if(key==\"TextRegion\"):\n",
    "            if(type(anno[\"TextRegion\"]) == list):\n",
    "                for j in range(len(anno[\"TextRegion\"])):\n",
    "                    text=anno[\"TextRegion\"][j]\n",
    "                    xmin=width\n",
    "                    ymin=height\n",
    "                    xmax=0\n",
    "                    ymax=0\n",
    "                    if(text[\"Coords\"]):\n",
    "                        if(text[\"Coords\"][\"Point\"]):\n",
    "                            for k in range(len(text[\"Coords\"][\"Point\"])):\n",
    "                                coordinates=anno[\"TextRegion\"][j][\"Coords\"][\"Point\"][k]\n",
    "                                xmin= min(xmin, int(coordinates['@x']));\n",
    "                                ymin= min(ymin, int(coordinates['@y']));\n",
    "                                xmax= min(max(xmax, int(coordinates['@x'])), width);\n",
    "                                ymax= min(max(ymax, int(coordinates['@y'])), height);\n",
    "                            if('@type' in text.keys()):    \n",
    "                                label_str+= str(xmin)+' '+str(ymin)+' '+str(xmax)+' '+str(ymax)+' '+text['@type']+' '\n",
    "                                if(xmax<=xmin or ymax<=ymin):\n",
    "                                    continue\n",
    "                                tbox=[];\n",
    "                                tbox.append(xmin)\n",
    "                                tbox.append(ymin)\n",
    "                                tbox.append(xmax)\n",
    "                                tbox.append(ymax)\n",
    "                                tbox.append(text['@type'])\n",
    "                                box.append(tbox)\n",
    "            else:\n",
    "                text=anno[\"TextRegion\"]\n",
    "                xmin=width\n",
    "                ymin=height\n",
    "                xmax=0\n",
    "                ymax=0\n",
    "                if(text[\"Coords\"]):\n",
    "                    if(text[\"Coords\"][\"Point\"]):\n",
    "                        for k in range(len(text[\"Coords\"][\"Point\"])):\n",
    "                            coordinates=anno[\"TextRegion\"][\"Coords\"][\"Point\"][k]\n",
    "                            xmin= min(xmin, int(coordinates['@x']));\n",
    "                            ymin= min(ymin, int(coordinates['@y']));\n",
    "                            xmax= min(max(xmax, int(coordinates['@x'])), width);\n",
    "                            ymax= min(max(ymax, int(coordinates['@y'])), height);\n",
    "                        if('@type' in text.keys()):    \n",
    "                            label_str+= str(xmin)+' '+str(ymin)+' '+str(xmax)+' '+str(ymax)+' '+text['@type']+' '\n",
    "                            if(xmax<=xmin or ymax<=ymin):\n",
    "                                continue\n",
    "                            tbox=[];\n",
    "                            tbox.append(xmin)\n",
    "                            tbox.append(ymin)\n",
    "                            tbox.append(xmax)\n",
    "                            tbox.append(ymax)\n",
    "                            tbox.append(text['@type'])\n",
    "                            box.append(tbox)\n",
    "        \n",
    "        else:\n",
    "            val=\"\"\n",
    "            if(key=='GraphicRegion'):\n",
    "                val=\"graphics\"\n",
    "                augment=True\n",
    "            elif(key=='ImageRegion'):\n",
    "                val=\"image\"\n",
    "            elif(key=='NoiseRegion'):\n",
    "                val=\"noise\"\n",
    "                augment=True\n",
    "            elif(key=='ChartRegion'):\n",
    "                val=\"chart\"\n",
    "                augment=True\n",
    "            elif(key=='TableRegion'):\n",
    "                val=\"table\"\n",
    "                augment=True\n",
    "            elif(key=='SeparatorRegion'):\n",
    "                val=\"separator\"\n",
    "            elif(key=='MathsRegion'):\n",
    "                val=\"maths\"\n",
    "                augment=True\n",
    "            elif(key=='LineDrawingRegion'):\n",
    "                val=\"linedrawing\"\n",
    "                augment=True\n",
    "            else:\n",
    "                val=\"frame\"\n",
    "                augment=True\n",
    "\n",
    "            \n",
    "            if(type(anno[key]) == list):\n",
    "                for j in range(len(anno[key])):\n",
    "                    text=anno[key][j]\n",
    "                    xmin=width\n",
    "                    ymin=height\n",
    "                    xmax=0\n",
    "                    ymax=0\n",
    "                    if(text[\"Coords\"]):\n",
    "                        if(text[\"Coords\"][\"Point\"]):\n",
    "                            for k in range(len(text[\"Coords\"][\"Point\"])):\n",
    "                                coordinates=anno[key][j][\"Coords\"][\"Point\"][k]\n",
    "                                xmin= min(xmin, int(coordinates['@x']));\n",
    "                                ymin= min(ymin, int(coordinates['@y']));\n",
    "                                xmax= min(max(xmax, int(coordinates['@x'])), width);\n",
    "                                ymax= min(max(ymax, int(coordinates['@y'])), height);\n",
    "                        label_str+= str(xmin)+' '+str(ymin)+' '+str(xmax)+' '+str(ymax)+' '+ val +' '\n",
    "                        if(xmax<=xmin or ymax<=ymin):\n",
    "                            continue\n",
    "                        tbox=[];\n",
    "                        tbox.append(xmin)\n",
    "                        tbox.append(ymin)\n",
    "                        tbox.append(xmax)\n",
    "                        tbox.append(ymax)\n",
    "                        tbox.append(val)\n",
    "                        box.append(tbox)\n",
    "            else:\n",
    "                text=anno[key]\n",
    "                xmin=width\n",
    "                ymin=height\n",
    "                xmax=0\n",
    "                ymax=0\n",
    "                if(text[\"Coords\"]):\n",
    "                    if(text[\"Coords\"][\"Point\"]):\n",
    "                        for k in range(len(text[\"Coords\"][\"Point\"])):\n",
    "                            coordinates=anno[key][\"Coords\"][\"Point\"][k]\n",
    "                            xmin= min(xmin, int(coordinates['@x']));\n",
    "                            ymin= min(ymin, int(coordinates['@y']));\n",
    "                            xmax= min(max(xmax, int(coordinates['@x'])), width);\n",
    "                            ymax= min(max(ymax, int(coordinates['@y'])), height);  \n",
    "                        label_str+= str(xmin)+' '+str(ymin)+' '+str(xmax)+' '+str(ymax)+' '+val+' '\n",
    "                        if(xmax<=xmin or ymax<=ymin):\n",
    "                            continue\n",
    "                        tbox=[];\n",
    "                        tbox.append(xmin)\n",
    "                        tbox.append(ymin)\n",
    "                        tbox.append(xmax)\n",
    "                        tbox.append(ymax)\n",
    "                        tbox.append(val)\n",
    "                        box.append(tbox)\n",
    "\n",
    "    label_str=label_str[:-1]\n",
    "    combined.append([fname, label_str])\n",
    "\n",
    "    if(augment):\n",
    "        augmentData(fname, box)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(combined, columns = ['ID', 'Label']);\n",
    "df.to_csv(final_root_dir + \"/train_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monk to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"Document_Layout_Analysis/\";\n",
    "img_dir = \"Images/\";\n",
    "anno_file = \"train_labels.csv\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = \"labels\";\n",
    "classes_file = \"classes.txt\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir_relative = root_dir + \"/\" + labels_dir\n",
    "if(not os.path.isdir(labels_dir_relative)):\n",
    "    os.mkdir(labels_dir_relative);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(root_dir + anno_file);\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "classes = [];\n",
    "for i in range(len(df)):\n",
    "    img_file = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(\" \");\n",
    "    for j in range(len(tmp)//5):\n",
    "        label = tmp[j*5 + 4];\n",
    "        if(label not in classes):\n",
    "            classes.append(label);\n",
    "classes = sorted(classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(root_dir + \"/\" + classes_file, 'w');\n",
    "for i in range(len(classes)):\n",
    "    f.write(classes[i]);\n",
    "    f.write(\"\\n\");\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(df))):\n",
    "    img_file = df[columns[0]][i];\n",
    "    labels = df[columns[1]][i];\n",
    "    tmp = labels.split(\" \");\n",
    "    fname = labels_dir_relative + \"/\" + img_file.split(\".\")[0] + \".txt\";\n",
    "    img = Image.open(root_dir + \"/\" + img_dir + \"/\" + img_file);\n",
    "    width, height = img.size\n",
    "    \n",
    "    f = open(fname, 'w');\n",
    "    for j in range(len(tmp)//5):\n",
    "        x1 = float(tmp[j*5 + 0]);\n",
    "        y1 = float(tmp[j*5 + 1]);\n",
    "        x2 = float(tmp[j*5 + 2]);\n",
    "        y2 = float(tmp[j*5 + 3]);\n",
    "        label = tmp[j*5 + 4];\n",
    "        \n",
    "        x_c = str(((x1 + x2)/2)/width);\n",
    "        y_c = str(((y1 + y2)/2)/height);\n",
    "        w = str((x2 - x1)/width);\n",
    "        h = str((y2 - y1)/height);\n",
    "        index = str(classes.index(label));\n",
    "        \n",
    "        f.write(index + \" \" + x_c + \" \" + y_c + \" \" + w + \" \" + h);\n",
    "        f.write(\"\\n\");\n",
    "    f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"Monk_Object_Detection/7_yolov3/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_detector import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Detector();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset directories\n",
    "img_dir = \"Document_Layout_Analysis/Images/\"\n",
    "label_dir = \"Document_Layout_Analysis/labels/\"\n",
    "class_list_file = \"Document_Layout_Analysis/classes.txt\"\n",
    "\n",
    "gtf.set_train_dataset(img_dir, label_dir, class_list_file, batch_size=16)\n",
    "gtf.set_val_dataset(img_dir, label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availale model types\n",
    "- \"yolov3\";\n",
    "- \"yolov3s\";\n",
    "- \"yolov3-spp\";\n",
    "- \"yolov3-spp3\";\n",
    "- \"yolov3-tiny\";\n",
    "- \"yolov3-spp-matrix\";\n",
    "- \"csresnext50-panet-spp\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting model as yolov3\n",
    "gtf.set_model(model_name=\"yolov3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    " - \"sgd\"\n",
    " - \"adam\"\n",
    " \n",
    " Set evolve as True if want to use evolving parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd is found out to perform better than adam optimiser on this task\n",
    "gtf.set_hyperparams(optimizer=\"sgd\", lr=0.003, multi_scale=False, evolve=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtf.Train(num_epochs=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import Image\n",
    "sys.path.append(\"Monk_Object_Detection/7_yolov3/lib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_detector import Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = Infer();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Document_Layout_Analysis/classes.txt\");\n",
    "class_list = f.readlines();\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"yolov3\";\n",
    "weights = \"weights/best.pt\";\n",
    "gtf.Model(model_name, class_list, weights, use_gpu=True, input_size=416);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Test_Images/test1.jpg\";\n",
    "gtf.Predict(img_path, conf_thres=0.3, iou_thres=0.5);\n",
    "Image(filename='output/test1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Test_Images/test2.jpg\";\n",
    "gtf.Predict(img_path, conf_thres=0.25, iou_thres=0.5);\n",
    "Image(filename='output/test2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path = \"Test_Images/test3.jpg\";\n",
    "gtf.Predict(img_path, conf_thres=0.2, iou_thres=0.5);\n",
    "Image(filename='output/test3.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "The outputs produced by YOLOv3 were very accurate. It’s the only model that was able to identify drop-capital among the 3 architectures. Though the confidence in the predictions is low compared to other models, their classification is most accurate among all three.\n",
    "\n",
    "If you want to use a model which shouldn’t take much time to train and missing minute details like footers or separators won’t affect your work, go for YOLOv3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
