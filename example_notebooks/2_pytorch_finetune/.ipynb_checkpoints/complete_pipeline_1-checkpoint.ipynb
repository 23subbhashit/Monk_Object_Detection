{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Directory Structure\n",
    "\n",
    "    Parent_Directory (root)\n",
    "          |\n",
    "          |-----------Images (img_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.jpg\n",
    "          |              |------------------img2.jpg\n",
    "          |              |------------------.........(and so on)\n",
    "          |\n",
    "          |\n",
    "          |-----------train_labels.csv (anno_file)\n",
    "          \n",
    "          \n",
    "## Annotation file format\n",
    "\n",
    "           | Id         | Labels                                 |\n",
    "           | img1.jpg   | x1 y1 x2 y2 label1 x1 y1 x2 y2 label2  |\n",
    "           \n",
    "- Labels:  xmin ymin xmax ymax label\n",
    "- xmin, ymin - top left corner of bounding box\n",
    "- xmax, ymax - bottom right corner of bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Data pre-prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"multi_object/kangaroo/kangaroo-master/\";                        #var1\n",
    "img_dir = \"Images/\";                                                    #var2\n",
    "anno_file = \"train_labels.csv\";                                         #var3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = pd.read_csv(root + anno_file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kangaroo']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = [];\n",
    "for i in range(len(train_list)):\n",
    "    label = train_list[\"Label\"][i];\n",
    "    tmp = label.split(\" \");\n",
    "    for j in range(len(tmp)//5):\n",
    "        if(tmp[(j*5+4)] not in label_list):\n",
    "            label_list.append(tmp[(j*5+4)])\n",
    "            \n",
    "sorted(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetMultiObject(object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.train_list = pd.read_csv(root + \"/train_labels.csv\");\n",
    "        self.label_list = self.get_labels();\n",
    "        self.num_classes = len(self.label_list) + 1;\n",
    "        \n",
    "    def get_labels(self):\n",
    "        label_list = [];\n",
    "        for i in range(len(self.train_list)):\n",
    "            label = self.train_list[\"Label\"][i];\n",
    "            tmp = label.split(\" \");\n",
    "            for j in range(len(tmp)//5):\n",
    "                if(tmp[(j*5+4)] not in label_list):\n",
    "                    label_list.append(tmp[(j*5+4)])\n",
    "        return sorted(label_list);\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_name = self.train_list[\"ID\"][idx];\n",
    "        label = self.train_list[\"Label\"][idx];\n",
    "        \n",
    "        \n",
    "        img_path = os.path.join(self.root, \"Images\",img_name)  \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        h, w = img.size;\n",
    "        tmp = label.split(\" \");\n",
    "        boxes = [];\n",
    "\n",
    "        num_objs = 0;\n",
    "        obj_ids = [];\n",
    "        for j in range(len(tmp)//5):\n",
    "            x1 = int(tmp[(j*5+0)]);\n",
    "            y1 = int(tmp[(j*5+1)]);\n",
    "            x2 = int(tmp[(j*5+2)]);\n",
    "            y2 = int(tmp[(j*5+3)]);\n",
    "            label = tmp[(j*5+4)];\n",
    "            boxes.append([x1, y1, x2, y2]);\n",
    "            obj_ids.append(self.label_list.index(label)+1);\n",
    "            num_objs += 1;\n",
    "        obj_ids = np.array(obj_ids, dtype=np.int64);\n",
    "        #print(obj_ids)\n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.as_tensor(obj_ids, dtype=torch.int64)\n",
    "        \n",
    "        #print(labels)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as T\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "dataset = CustomDatasetMultiObject(root, get_transform(train=True))\n",
    "dataset_test = CustomDatasetMultiObject(root, get_transform(train=False))\n",
    "num_classes = dataset.num_classes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in train and test set\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=1, shuffle=True, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "# load a pre-trained model for classification and return\n",
    "# only the features\n",
    "backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
    "# FasterRCNN needs to know the number of\n",
    "# output channels in a backbone. For mobilenet_v2, it's 1280\n",
    "# so we need to add it here\n",
    "backbone.out_channels = 1280\n",
    "\n",
    "# let's make the RPN generate 5 x 3 anchors per spatial\n",
    "# location, with 5 different sizes and 3 different aspect\n",
    "# ratios. We have a Tuple[Tuple[int]] because each feature\n",
    "# map could potentially have different sizes and\n",
    "# aspect ratios\n",
    "anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                   aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "# let's define what are the feature maps that we will\n",
    "# use to perform the region of interest cropping, as well as\n",
    "# the size of the crop after rescaling.\n",
    "# if your backbone returns a Tensor, featmap_names is expected to\n",
    "# be [0]. More generally, the backbone should return an\n",
    "# OrderedDict[Tensor], and in featmap_names you can choose which\n",
    "# feature maps to use.\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n",
    "                                                output_size=7,\n",
    "                                                sampling_ratio=2)\n",
    "\n",
    "# put the pieces together inside a FasterRCNN model\n",
    "model = FasterRCNN(backbone,\n",
    "                   num_classes=num_classes,\n",
    "                   rpn_anchor_generator=anchor_generator,\n",
    "                   box_roi_pool=roi_pooler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/114]  eta: 0:03:28  lr: 0.000049  loss: 1.4710 (1.4710)  loss_classifier: 0.7212 (0.7212)  loss_box_reg: 0.0398 (0.0398)  loss_objectness: 0.6488 (0.6488)  loss_rpn_box_reg: 0.0611 (0.0611)  time: 1.8326  data: 0.4310  max mem: 1912\n",
      "Epoch: [0]  [ 10/114]  eta: 0:00:38  lr: 0.000491  loss: 1.3886 (1.3089)  loss_classifier: 0.5579 (0.5122)  loss_box_reg: 0.0513 (0.0528)  loss_objectness: 0.6559 (0.6544)  loss_rpn_box_reg: 0.0694 (0.0895)  time: 0.3742  data: 0.0419  max mem: 2566\n",
      "Epoch: [0]  [ 20/114]  eta: 0:00:28  lr: 0.000933  loss: 1.0678 (1.0848)  loss_classifier: 0.2570 (0.3554)  loss_box_reg: 0.0614 (0.0649)  loss_objectness: 0.6074 (0.5920)  loss_rpn_box_reg: 0.0450 (0.0725)  time: 0.2287  data: 0.0031  max mem: 2566\n",
      "Epoch: [0]  [ 30/114]  eta: 0:00:23  lr: 0.001375  loss: 0.8066 (0.9565)  loss_classifier: 0.1772 (0.3153)  loss_box_reg: 0.0641 (0.0673)  loss_objectness: 0.4139 (0.5066)  loss_rpn_box_reg: 0.0420 (0.0673)  time: 0.2291  data: 0.0031  max mem: 2566\n",
      "Epoch: [0]  [ 40/114]  eta: 0:00:19  lr: 0.001817  loss: 0.6766 (0.8763)  loss_classifier: 0.2094 (0.2883)  loss_box_reg: 0.0686 (0.0702)  loss_objectness: 0.2700 (0.4402)  loss_rpn_box_reg: 0.0541 (0.0775)  time: 0.2327  data: 0.0031  max mem: 2566\n",
      "Epoch: [0]  [ 50/114]  eta: 0:00:16  lr: 0.002259  loss: 0.4907 (0.7954)  loss_classifier: 0.1708 (0.2638)  loss_box_reg: 0.0724 (0.0714)  loss_objectness: 0.1805 (0.3840)  loss_rpn_box_reg: 0.0545 (0.0762)  time: 0.2328  data: 0.0033  max mem: 2566\n",
      "Epoch: [0]  [ 60/114]  eta: 0:00:13  lr: 0.002701  loss: 0.4684 (0.7518)  loss_classifier: 0.1708 (0.2521)  loss_box_reg: 0.0936 (0.0762)  loss_objectness: 0.1501 (0.3474)  loss_rpn_box_reg: 0.0460 (0.0761)  time: 0.2288  data: 0.0032  max mem: 2569\n",
      "Epoch: [0]  [ 70/114]  eta: 0:00:10  lr: 0.003143  loss: 0.4684 (0.7182)  loss_classifier: 0.1597 (0.2382)  loss_box_reg: 0.0883 (0.0760)  loss_objectness: 0.1346 (0.3223)  loss_rpn_box_reg: 0.0545 (0.0817)  time: 0.2195  data: 0.0031  max mem: 2569\n",
      "Epoch: [0]  [ 80/114]  eta: 0:00:08  lr: 0.003585  loss: 0.4326 (0.6833)  loss_classifier: 0.1568 (0.2298)  loss_box_reg: 0.0822 (0.0793)  loss_objectness: 0.1232 (0.2973)  loss_rpn_box_reg: 0.0384 (0.0769)  time: 0.2049  data: 0.0030  max mem: 2569\n",
      "Epoch: [0]  [ 90/114]  eta: 0:00:05  lr: 0.004028  loss: 0.4167 (0.6640)  loss_classifier: 0.1430 (0.2201)  loss_box_reg: 0.0752 (0.0790)  loss_objectness: 0.1220 (0.2818)  loss_rpn_box_reg: 0.0384 (0.0830)  time: 0.2106  data: 0.0031  max mem: 2569\n",
      "Epoch: [0]  [100/114]  eta: 0:00:03  lr: 0.004470  loss: 0.4326 (0.6502)  loss_classifier: 0.1269 (0.2115)  loss_box_reg: 0.0584 (0.0776)  loss_objectness: 0.1188 (0.2672)  loss_rpn_box_reg: 0.1047 (0.0938)  time: 0.2278  data: 0.0031  max mem: 2570\n",
      "Epoch: [0]  [110/114]  eta: 0:00:00  lr: 0.004912  loss: 0.4326 (0.6326)  loss_classifier: 0.1030 (0.2026)  loss_box_reg: 0.0448 (0.0757)  loss_objectness: 0.1181 (0.2577)  loss_rpn_box_reg: 0.0800 (0.0966)  time: 0.2306  data: 0.0031  max mem: 2570\n",
      "Epoch: [0]  [113/114]  eta: 0:00:00  lr: 0.005000  loss: 0.3884 (0.6248)  loss_classifier: 0.1030 (0.1996)  loss_box_reg: 0.0420 (0.0748)  loss_objectness: 0.1181 (0.2541)  loss_rpn_box_reg: 0.0670 (0.0963)  time: 0.2281  data: 0.0030  max mem: 2570\n",
      "Epoch: [0] Total time: 0:00:27 (0.2392 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/50]  eta: 0:00:09  model_time: 0.0382 (0.0382)  evaluator_time: 0.0225 (0.0225)  time: 0.1909  data: 0.1290  max mem: 2570\n",
      "Test:  [49/50]  eta: 0:00:00  model_time: 0.0365 (0.0379)  evaluator_time: 0.0010 (0.0015)  time: 0.0433  data: 0.0027  max mem: 2570\n",
      "Test: Total time: 0:00:02 (0.0465 s / it)\n",
      "Averaged stats: model_time: 0.0365 (0.0379)  evaluator_time: 0.0010 (0.0015)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.064\n",
      "Epoch: [1]  [  0/114]  eta: 0:00:38  lr: 0.005000  loss: 0.3504 (0.3504)  loss_classifier: 0.1297 (0.1297)  loss_box_reg: 0.0649 (0.0649)  loss_objectness: 0.1468 (0.1468)  loss_rpn_box_reg: 0.0089 (0.0089)  time: 0.3412  data: 0.1334  max mem: 2570\n",
      "Epoch: [1]  [ 10/114]  eta: 0:00:24  lr: 0.005000  loss: 0.2928 (0.3538)  loss_classifier: 0.0591 (0.0876)  loss_box_reg: 0.0399 (0.0500)  loss_objectness: 0.1150 (0.1139)  loss_rpn_box_reg: 0.0741 (0.1023)  time: 0.2380  data: 0.0161  max mem: 2570\n",
      "Epoch: [1]  [ 20/114]  eta: 0:00:21  lr: 0.005000  loss: 0.2928 (0.3305)  loss_classifier: 0.0648 (0.0861)  loss_box_reg: 0.0399 (0.0524)  loss_objectness: 0.1056 (0.1089)  loss_rpn_box_reg: 0.0738 (0.0831)  time: 0.2281  data: 0.0037  max mem: 2570\n",
      "Epoch: [1]  [ 30/114]  eta: 0:00:19  lr: 0.005000  loss: 0.2824 (0.3168)  loss_classifier: 0.0707 (0.0844)  loss_box_reg: 0.0516 (0.0520)  loss_objectness: 0.0774 (0.1030)  loss_rpn_box_reg: 0.0428 (0.0775)  time: 0.2305  data: 0.0031  max mem: 2570\n",
      "Epoch: [1]  [ 40/114]  eta: 0:00:17  lr: 0.005000  loss: 0.2723 (0.3213)  loss_classifier: 0.0699 (0.0822)  loss_box_reg: 0.0508 (0.0517)  loss_objectness: 0.0735 (0.1032)  loss_rpn_box_reg: 0.0428 (0.0843)  time: 0.2332  data: 0.0031  max mem: 2570\n",
      "Epoch: [1]  [ 50/114]  eta: 0:00:14  lr: 0.005000  loss: 0.2723 (0.3403)  loss_classifier: 0.0710 (0.0859)  loss_box_reg: 0.0609 (0.0570)  loss_objectness: 0.0883 (0.1068)  loss_rpn_box_reg: 0.0505 (0.0906)  time: 0.2329  data: 0.0031  max mem: 2574\n",
      "Epoch: [1]  [ 60/114]  eta: 0:00:12  lr: 0.005000  loss: 0.2978 (0.3443)  loss_classifier: 0.0683 (0.0836)  loss_box_reg: 0.0609 (0.0556)  loss_objectness: 0.1001 (0.1072)  loss_rpn_box_reg: 0.0789 (0.0981)  time: 0.2311  data: 0.0031  max mem: 2574\n",
      "Epoch: [1]  [ 70/114]  eta: 0:00:10  lr: 0.005000  loss: 0.2978 (0.3496)  loss_classifier: 0.0802 (0.0860)  loss_box_reg: 0.0488 (0.0583)  loss_objectness: 0.1001 (0.1073)  loss_rpn_box_reg: 0.0611 (0.0981)  time: 0.2307  data: 0.0032  max mem: 2574\n",
      "Epoch: [1]  [ 80/114]  eta: 0:00:07  lr: 0.005000  loss: 0.2970 (0.3431)  loss_classifier: 0.0979 (0.0870)  loss_box_reg: 0.0662 (0.0598)  loss_objectness: 0.0899 (0.1050)  loss_rpn_box_reg: 0.0415 (0.0913)  time: 0.2320  data: 0.0032  max mem: 2574\n",
      "Epoch: [1]  [ 90/114]  eta: 0:00:05  lr: 0.005000  loss: 0.2784 (0.3376)  loss_classifier: 0.0914 (0.0877)  loss_box_reg: 0.0698 (0.0614)  loss_objectness: 0.0734 (0.1018)  loss_rpn_box_reg: 0.0415 (0.0867)  time: 0.2299  data: 0.0030  max mem: 2574\n",
      "Epoch: [1]  [100/114]  eta: 0:00:03  lr: 0.005000  loss: 0.2685 (0.3377)  loss_classifier: 0.0931 (0.0908)  loss_box_reg: 0.0692 (0.0644)  loss_objectness: 0.0593 (0.1007)  loss_rpn_box_reg: 0.0277 (0.0817)  time: 0.2280  data: 0.0030  max mem: 2574\n",
      "Epoch: [1]  [110/114]  eta: 0:00:00  lr: 0.005000  loss: 0.2504 (0.3352)  loss_classifier: 0.0723 (0.0898)  loss_box_reg: 0.0601 (0.0639)  loss_objectness: 0.0655 (0.1001)  loss_rpn_box_reg: 0.0388 (0.0813)  time: 0.2292  data: 0.0030  max mem: 2574\n",
      "Epoch: [1]  [113/114]  eta: 0:00:00  lr: 0.005000  loss: 0.2417 (0.3330)  loss_classifier: 0.0804 (0.0894)  loss_box_reg: 0.0601 (0.0640)  loss_objectness: 0.0595 (0.0987)  loss_rpn_box_reg: 0.0388 (0.0809)  time: 0.2272  data: 0.0029  max mem: 2574\n",
      "Epoch: [1] Total time: 0:00:26 (0.2316 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/50]  eta: 0:00:08  model_time: 0.0464 (0.0464)  evaluator_time: 0.0027 (0.0027)  time: 0.1735  data: 0.1232  max mem: 2574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [49/50]  eta: 0:00:00  model_time: 0.0521 (0.0522)  evaluator_time: 0.0016 (0.0016)  time: 0.0580  data: 0.0027  max mem: 2574\n",
      "Test: Total time: 0:00:03 (0.0607 s / it)\n",
      "Averaged stats: model_time: 0.0521 (0.0522)  evaluator_time: 0.0016 (0.0016)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n",
      "That's it!\n"
     ]
    }
   ],
   "source": [
    "# get the model using our helper function\n",
    "#model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)\n",
    "\n",
    "# let's train it for 10 epochs\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
