{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tessellate-Imaging/Monk_Object_Detection/blob/master/example_notebooks/1_gluoncv_finetune/Convert%20Pascal%20VOC%20Annotations%20to%20Desired%20Format.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    " - Run these commands\n",
    "     \n",
    "     - git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n",
    "     \n",
    "     - cd Monk_Object_Detection/1_gluoncv_finetune/installation\n",
    "     \n",
    " - Select the right requirements file and run\n",
    " \n",
    "     - cat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colab use the command below\n",
    "! cd Monk_Object_Detection/1_gluoncv_finetune/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install\n",
    "\n",
    "\n",
    "# For Local systems and cloud select the right CUDA version\n",
    "# !cd Monk_Object_Detection/1_gluoncv_finetune/installation && cat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Directory Structure - Required\n",
    "\n",
    "    Parent_Directory (root)\n",
    "          |\n",
    "          |-----------Images (img_dir)\n",
    "          |              |\n",
    "          |              |------------------img1.jpg\n",
    "          |              |------------------img2.jpg\n",
    "          |              |------------------.........(and so on)\n",
    "          |\n",
    "          |\n",
    "          |-----------train_labels.csv (anno_file)\n",
    "          \n",
    "          \n",
    "## Annotation file format\n",
    "\n",
    "           | Id         | Labels                                 |\n",
    "           | img1.jpg   | x1 y1 x2 y2 label1 x1 y1 x2 y2 label2  |\n",
    "           \n",
    "- Labels:  xmin ymin xmax ymax label\n",
    "- xmin, ymin - top left corner of bounding box\n",
    "- xmax, ymax - bottom right corner of bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Dataset Credits\n",
    "\n",
    "- credits: https://github.com/wujixiu/helmet-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Convert pascal voc format to desired format we need to create an annotation csv file from the set of xml annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xmltodict\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"Monk_Object_Detection/example_notebooks/sample_dataset/sample_pascal_voc/\";\n",
    "img_dir = \"Images/\";\n",
    "anno_dir = \"Annotations/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(root_dir + anno_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2288f159cbf540538cb3ebda1a297c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "combined = [];\n",
    "for i in tqdm(range(len(files))):\n",
    "    annoFile = root_dir + \"/\" + anno_dir + \"/\" + files[i];\n",
    "    f = open(annoFile, 'r');\n",
    "    my_xml = f.read();\n",
    "    anno = dict(dict(xmltodict.parse(my_xml))[\"annotation\"])\n",
    "    fname = anno[\"filename\"];\n",
    "    label_str = \"\";\n",
    "    if(type(anno[\"object\"]) == list):\n",
    "        for j in range(len(anno[\"object\"])):\n",
    "            obj = dict(anno[\"object\"][j]);\n",
    "            label = anno[\"object\"][j][\"name\"];\n",
    "            bbox = dict(anno[\"object\"][j][\"bndbox\"])\n",
    "            x1 = bbox[\"xmin\"];\n",
    "            y1 = bbox[\"ymin\"];\n",
    "            x2 = bbox[\"xmax\"];\n",
    "            y2 = bbox[\"ymax\"];\n",
    "            if(j == len(anno[\"object\"])-1):\n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "            else:        \n",
    "                label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label + \" \";\n",
    "    else:\n",
    "        obj = dict(anno[\"object\"]);\n",
    "        label = anno[\"object\"][\"name\"];\n",
    "        bbox = dict(anno[\"object\"][\"bndbox\"])\n",
    "        x1 = bbox[\"xmin\"];\n",
    "        y1 = bbox[\"ymin\"];\n",
    "        x2 = bbox[\"xmax\"];\n",
    "        y2 = bbox[\"ymax\"];\n",
    "        \n",
    "        label_str += x1 + \" \" + y1 + \" \" + x2 + \" \" + y2 + \" \" + label;\n",
    "    \n",
    "    \n",
    "    combined.append([fname, label_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['00007.jpg', '218 100 312 211 yellow 523 154 547 185 white'],\n",
       " ['00004.jpg', '792 124 1020 395 red '],\n",
       " ['00009.jpg', '364 477 536 701 yellow 543 448 712 694 yellow'],\n",
       " ['00003.jpg', '428 553 481 625 red 250 575 259 586 red 261 565 271 580 red'],\n",
       " ['00006.jpg', '181 163 206 190 yellow 268 175 287 200 yellow'],\n",
       " ['00008.jpg', '160 2 555 391 yellow '],\n",
       " ['00000.jpg',\n",
       "  '9 111 61 182 white 95 138 143 197 white 185 98 235 166 white 262 125 311 192 white 334 89 382 156 white 429 98 474 163 white 503 100 552 166 white 588 115 637 177 white 694 92 743 164 white 763 57 821 129 white 827 71 869 129 white 860 89 915 155 white 922 67 1001 155 white'],\n",
       " ['00002.jpg', '249 76 353 191 red '],\n",
       " ['00001.jpg', '323 55 491 263 red 640 117 838 331 red'],\n",
       " ['00010.jpg',\n",
       "  '181 83 209 127 red 208 114 233 146 red 268 117 292 146 red 348 61 405 123 red 303 103 340 146 none 115 107 137 138 none 67 110 91 135 none 28 96 61 138 none']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(combined, columns = ['ID', 'Label']);\n",
    "df.to_csv(root_dir + \"/train_labels.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author - Tessellate Imaging - https://www.tessellateimaging.com/\n",
    "\n",
    "# Monk Library - https://github.com/Tessellate-Imaging/monk_v1\n",
    "\n",
    "    Monk is an opensource low-code tool for computer vision and deep learning\n",
    "\n",
    "\n",
    "## Monk features\n",
    "   - low-code\n",
    "   - unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n",
    "   - syntax invariant wrapper\n",
    "\n",
    "## Enables\n",
    "\n",
    "    - to create, manage and version control deep learning experiments\n",
    "    - to compare experiments across training metrics\n",
    "    - to quickly find best hyper-parameters\n",
    "\n",
    "## At present it only supports transfer learning, but we are working each day to incorporate\n",
    "\n",
    "    - GUI based custom model creation\n",
    "    - various object detection and segmentation algorithms\n",
    "    - deployment pipelines to cloud and local platforms\n",
    "    - acceleration libraries such as TensorRT\n",
    "    - preprocessing and post processing libraries\n",
    "\n",
    "\n",
    "## To contribute to Monk AI or Monk Object Detection repository raise an issue in the git-repo or dm us on linkedin\n",
    "\n",
    "    - Abhishek - https://www.linkedin.com/in/abhishek-kumar-annamraju/\n",
    "    - Akash - https://www.linkedin.com/in/akashdeepsingh01/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
